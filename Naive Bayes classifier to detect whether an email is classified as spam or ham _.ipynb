{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cd78ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import makedirs, path, remove, rename, rmdir\n",
    "from tarfile import open as open_tar\n",
    "from shutil import rmtree\n",
    "from urllib import request, parse\n",
    "from glob import glob\n",
    "from os import path\n",
    "from re import sub\n",
    "from email import message_from_file\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score)\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0066917d",
   "metadata": {},
   "source": [
    "### Downloading the emails to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cadbd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_corpus(dataset_dir: str = 'data'):\n",
    "    base_url = 'https://spamassassin.apache.org'\n",
    "    corpus_path = 'old/publiccorpus'\n",
    "    files = {\n",
    "        '20021010_easy_ham.tar.bz2': 'ham',\n",
    "        '20021010_hard_ham.tar.bz2': 'ham',\n",
    "        '20021010_spam.tar.bz2': 'spam',\n",
    "        '20030228_easy_ham.tar.bz2': 'ham',\n",
    "        '20030228_easy_ham_2.tar.bz2': 'ham',\n",
    "        '20030228_hard_ham.tar.bz2': 'ham',\n",
    "        '20030228_spam.tar.bz2': 'spam',\n",
    "        '20030228_spam_2.tar.bz2': 'spam',\n",
    "        '20050311_spam_2.tar.bz2': 'spam' }\n",
    "\n",
    "    #creates the folders: downloads, ham and spam\n",
    "    downloads_dir = path.join(dataset_dir, 'downloads')\n",
    "    ham_dir = path.join(dataset_dir, 'ham')\n",
    "    spam_dir = path.join(dataset_dir, 'spam')\n",
    "\n",
    "    makedirs(downloads_dir, exist_ok=True)\n",
    "    makedirs(ham_dir, exist_ok=True)\n",
    "    makedirs(spam_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    for file, spam_or_ham in files.items():\n",
    "        # download files from URL of each specific .bz2 file\n",
    "        url = parse.urljoin(base_url, f'{corpus_path}/{file}')\n",
    "        tar_filename = path.join(downloads_dir, file)\n",
    "        request.urlretrieve(url, tar_filename)\n",
    "\n",
    "        #list e-mails in the compressed .bz2 file\n",
    "        emails = []\n",
    "        with open_tar(tar_filename) as tar:\n",
    "            tar.extractall(path=downloads_dir)\n",
    "            for tarinfo in tar:\n",
    "                if len(tarinfo.name.split('/')) > 1:\n",
    "                    emails.append(tarinfo.name)\n",
    "\n",
    "        # move e-mails to ham or spam directory\n",
    "        for email in emails:\n",
    "            directory, filename = email.split('/')\n",
    "            directory = path.join(downloads_dir, directory)\n",
    "\n",
    "            if not path.exists(path.join(dataset_dir, spam_or_ham, filename)):\n",
    "                rename(path.join(directory, filename),\n",
    "                   path.join(dataset_dir, spam_or_ham, filename))\n",
    "\n",
    "        rmtree(directory)\n",
    "\n",
    "download_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95bb444",
   "metadata": {},
   "source": [
    "### How many e-mails are classified in our dataset as either Spam or not Spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b5cbf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Non-Spam E-mails: 6952\n",
      "\n",
      "Number of Spam E-mails: 2399\n"
     ]
    }
   ],
   "source": [
    "#How many e-mails are classified in our dataset as either Spam or not Spam?\n",
    "ham_dir = path.join('data', 'ham')\n",
    "spam_dir = path.join('data', 'spam')\n",
    "\n",
    "print('Number of Non-Spam E-mails:', len(glob(f'{ham_dir}/*')))\n",
    "print('\\nNumber of Spam E-mails:', len(glob(f'{spam_dir}/*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c6646",
   "metadata": {},
   "source": [
    "### Classifier based on Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4634e4bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'listdir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m ham_dir \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mham\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m spam_dir \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m ham_emails \u001b[38;5;241m=\u001b[39m read_emails(ham_dir)\n\u001b[0;32m     30\u001b[0m spam_emails \u001b[38;5;241m=\u001b[39m read_emails(spam_dir)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Create labels\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m, in \u001b[0;36mread_emails\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_emails\u001b[39m(directory):\n\u001b[0;32m      3\u001b[0m     emails \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m listdir(directory):\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path\u001b[38;5;241m.\u001b[39mjoin(directory, file), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m             \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'listdir' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to read emails from files\n",
    "def read_emails(directory):\n",
    "    emails = []\n",
    "    for file in listdir(directory):\n",
    "        with open(path.join(directory, file), 'r', encoding='latin1') as f:\n",
    "            try:\n",
    "                email = message_from_file(f)\n",
    "                body = ''\n",
    "                if email.is_multipart():\n",
    "                    for part in email.walk():\n",
    "                        if part.get_content_type() == 'text/plain':\n",
    "                            body += part.get_payload()\n",
    "                else:\n",
    "                    body = email.get_payload()\n",
    "                emails.append(body)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file}: {e}\")\n",
    "    return emails\n",
    "\n",
    "# Directories\n",
    "dataset_dir = 'data'\n",
    "download_corpus(dataset_dir)\n",
    "\n",
    "# Read emails\n",
    "\n",
    "ham_dir = path.join('data', 'ham')\n",
    "spam_dir = path.join('data', 'spam')\n",
    "\n",
    "ham_emails = read_emails(ham_dir)\n",
    "spam_emails = read_emails(spam_dir)\n",
    "\n",
    "# Create labels\n",
    "ham_labels = np.zeros(len(ham_emails))\n",
    "spam_labels = np.ones(len(spam_emails))\n",
    "\n",
    "# Concatenate ham and spam emails\n",
    "all_emails = ham_emails + spam_emails\n",
    "all_labels = np.concatenate([ham_labels, spam_labels])\n",
    "\n",
    "# Vectorize emails\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(all_emails)\n",
    "\n",
    "# Train-test split\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_index, test_index = next(stratified_split.split(X, all_labels))\n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = all_labels[train_index], all_labels[test_index]\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0afb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email import message_from_string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Given email\n",
    "email_text = \"\"\"\n",
    "Subject: Get Rich Quick!\n",
    "\n",
    "Dear Friend,\n",
    "\n",
    "Congratulations! You've been selected to participate in an exclusive opportunity to make thousands of dollars from the comfort of your own home. Our revolutionary system guarantees quick and easy cash with minimal effort.\n",
    "\n",
    "No more struggling to pay bills or worrying about financial security. With our proven method, you can start earning massive amounts of money in no time.\n",
    "\n",
    "Here's what some of our satisfied customers have to say:\n",
    "- \"I was skeptical at first, but I'm now living my dream life thanks to this incredible system!\" - John S.\n",
    "- \"I never thought making money online could be this simple. It's changed my life!\" - Sarah L.\n",
    "\n",
    "Don't miss out on this limited-time offer. Act now to secure your spot and start enjoying a life of financial freedom.\n",
    "\n",
    "Click the link below to get started:\n",
    "www.getrichquick.com\n",
    "\n",
    "Remember, this opportunity is exclusive and won't last long. Take control of your financial future today!\n",
    "\n",
    "Best regards,\n",
    "The Get Rich Quick Team\n",
    "\"\"\"\n",
    "\n",
    "vectorizer = CountVectorizer() # Vectorize the email\n",
    "X_email = vectorizer.fit_transform([email_text])\n",
    "\n",
    "y_email_pred = naive_bayes.predict(X_email) # Predict using the trained Naive Bayes classifier\n",
    "\n",
    "if y_email_pred[0] == 0:\n",
    "    print(\"The email is classified as HAM (not spam).\")\n",
    "else:\n",
    "    print(\"The email is classified as SPAM.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
