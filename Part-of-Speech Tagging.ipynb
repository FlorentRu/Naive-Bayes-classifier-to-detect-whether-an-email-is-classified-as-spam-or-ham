{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c637581",
   "metadata": {},
   "source": [
    "### Part-of-Speech Tagging Rule-Based and Statistical-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a17449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\flore\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\flore\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\flore\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\flore\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('treebank')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker') #The maxent_ne_chunker contains two pre-trained English named entity chunkers trained on an ACE corpus (perhaps ACE ACE 2004 Multilingual Training Corpus?)\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c88de46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger #important for POS tagging\n",
    "\n",
    "\n",
    "# Part 1: Rule-based and Statistical Approaches for Part-of-Speech Tagging\n",
    "\n",
    "# Rule-based POS Tagger\n",
    "def rule_based_pos_tagger(sentence):\n",
    "    # Define your rules here\n",
    "    rules = [\n",
    "          (re.compile(r'\\bThe\\b'), 'DT'),\n",
    "          (re.compile(r'\\bcat\\b'), 'NN'),\n",
    "          (re.compile(r'\\bis\\b'), 'VB'),\n",
    "          (re.compile(r'\\bsitting\\b'), 'VB'),\n",
    "          (re.compile(r'\\bon\\b'), 'IN'),\n",
    "          (re.compile(r'\\bthe\\b'), 'DT'),\n",
    "          (re.compile(r'\\bmat\\b'), 'NN'),\n",
    "      ]\n",
    "    tagged_sentence = []\n",
    "    words = word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        for pattern, tag in rules:\n",
    "            if pattern.match(word):\n",
    "                tagged_sentence.append((word, tag))\n",
    "                break\n",
    "        else:\n",
    "            tagged_sentence.append((word, 'UNKNOWN'))\n",
    "    return tagged_sentence\n",
    "\n",
    "# Statistical POS Tagger\n",
    "def statistical_pos_tagger(sentence):\n",
    "    # Train your model on a labeled corpus (e.g., treebank)\n",
    "    train_data = treebank.tagged_sents()[:3000]\n",
    "    # Train your statistical model here\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(len(train_data) * 0.8)\n",
    "    train_set = train_data[:train_size]\n",
    "    test_set = train_data[train_size:]\n",
    "\n",
    "    # Create taggers\n",
    "    default_tagger = DefaultTagger('NN')  # Default tagger assigns 'NN' to all words\n",
    "    unigram_tagger = UnigramTagger(train_set, backoff=default_tagger)  # Unigram tagger using training set\n",
    "    bigram_tagger = BigramTagger(train_set, backoff=unigram_tagger)  # Bigram tagger using training set and fallback to unigram tagger\n",
    "\n",
    "    # Evaluate on test set\n",
    "    accuracy = bigram_tagger.accuracy(test_set)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "    # Apply the trained model to tag the sentence\n",
    "    tagged_sentence  = bigram_tagger.tag(word_tokenize(sentence))\n",
    "    #tagged_sentence = nltk.pos_tag(words)\n",
    "    #tagged_sentence.append(tagged_sentence)\n",
    "    return tagged_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6f9ab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule-based POS Tags:\n",
      "[('The', 'DT'), ('cat', 'NN'), ('is', 'VB'), ('sitting', 'VB'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', 'UNKNOWN')]\n",
      "Accuracy: 0.8748033560566335\n",
      "Statistical POS Tags:\n",
      "[('The', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Part 1: Rule-based and Statistical Approaches for Part-of-Speech Tagging\n",
    "sample_sentence = \"The cat is sitting on the mat.\"\n",
    "\n",
    "# Rule-based POS Tagging\n",
    "rule_based_tags = rule_based_pos_tagger(sample_sentence)\n",
    "print(\"Rule-based POS Tags:\")\n",
    "print(rule_based_tags)\n",
    "\n",
    "# Statistical POS Tagging\n",
    "statistical_tags = statistical_pos_tagger(sample_sentence)\n",
    "print(\"Statistical POS Tags:\")\n",
    "print(statistical_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a19004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"The cat is sitting on the mat.\"\n",
    "\n",
    "tagged_sentence = nltk.pos_tag(word_tokenize(sample_sentence))\n",
    "print(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5a4aa88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('\\\\b\\\\w+s\\\\b|\\\\b\\\\w+es\\\\b', 'NN'),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r'\\b\\w+s\\b|\\b\\w+es\\b', 'NN'),     # Nouns ending ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0f2be39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Rule-based POS Tags:\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('while', 'IN'), ('it', 'UNKNOWN'), (\"'s\", 'UNKNOWN'), ('raining', 'VBG'), ('heavily', 'RB'), ('.', 'UNKNOWN')]\n",
      "Accuracy: 0.8748033560566335\n",
      "Updated Statistical POS Tags:\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'NN'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'NN'), ('dog', 'NN'), ('while', 'IN'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('raining', 'NN'), ('heavily', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "def updated_rule_based_pos_tagger(sentence): # Here is pdated Rule-based POS Tagger\n",
    "    \n",
    "    # Definition of the Rules\n",
    "    \n",
    "    rules = [     \n",
    "          (re.compile(r'\\bThe\\b'), 'DT'),\n",
    "          (re.compile(r'\\bquick\\b'), 'JJ'),\n",
    "          (re.compile(r'\\bbrown\\b'), 'JJ'),\n",
    "          (re.compile(r'\\bfox\\b'), 'NN'),\n",
    "          (re.compile(r'\\bjumps\\b'), 'VBZ'),\n",
    "          (re.compile(r'\\bover\\b'), 'IN'),\n",
    "          (re.compile(r'\\bthe\\b'), 'DT'),\n",
    "          (re.compile(r'\\blazy\\b'), 'JJ'),\n",
    "          (re.compile(r'\\bdog\\b'), 'NN'),\n",
    "          (re.compile(r'\\bwhile\\b'), 'IN'),\n",
    "          (re.compile(r'\\bit\\'s\\b'), 'NN'), \n",
    "          (re.compile(r'\\braining\\b'), 'VBG'),\n",
    "          (re.compile(r'\\bheavily\\b'), 'RB')\n",
    "      ]\n",
    "    tagged_sentence = []\n",
    "    words = word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        for pattern, tag in rules:\n",
    "            if pattern.match(word):\n",
    "                tagged_sentence.append((word, tag))\n",
    "                break\n",
    "        else:\n",
    "            tagged_sentence.append((word, 'UNKNOWN'))\n",
    "    return tagged_sentence\n",
    "\n",
    "def updated_statistical_pos_tagger(sentence): # Let's updated Statistical POS Tagger\n",
    "    \n",
    "    # Let's train the model on a labeled corpus\n",
    "    train_data = treebank.tagged_sents()[:3000]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(len(train_data) * 0.8)\n",
    "    train_set = train_data[:train_size]\n",
    "    test_set = train_data[train_size:]\n",
    "\n",
    "    # Create taggers\n",
    "    default_tagger = DefaultTagger('NN')  # Default tagger assigns 'NN' to all words\n",
    "    unigram_tagger = UnigramTagger(train_set, backoff=default_tagger)  # Unigram tagger using training set\n",
    "    bigram_tagger = BigramTagger(train_set, backoff=unigram_tagger)  # Bigram tagger using training set and fallback to unigram tagger\n",
    "\n",
    "    # Evaluate on test set\n",
    "    accuracy = bigram_tagger.accuracy(test_set)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "    # Apply the trained model to tag the sentence\n",
    "    tagged_sentence  = bigram_tagger.tag(word_tokenize(sentence))\n",
    "    return tagged_sentence\n",
    "\n",
    "# Updated Rule-based POS Tagger\n",
    "updated_rule_based_tags = updated_rule_based_pos_tagger(\"The quick brown fox jumps over the lazy dog while it's raining heavily.\")\n",
    "print(\"Updated Rule-based POS Tags:\")\n",
    "print(updated_rule_based_tags)\n",
    "\n",
    "# Updated Statistical POS Tagger\n",
    "updated_statistical_tags = updated_statistical_pos_tagger(\"The quick brown fox jumps over the lazy dog while it's raining heavily.\")\n",
    "print(\"Updated Statistical POS Tags:\")\n",
    "print(updated_statistical_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
